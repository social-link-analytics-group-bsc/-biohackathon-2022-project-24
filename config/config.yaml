api_europepmc_params:
  rest_articles:
    root_url: https://www.ebi.ac.uk/europepmc/webservices/rest/
  oai_service:
    root_url: http://europepmc.org/oai.cgi 
  annotations_api:
    root_url: http://www.ebi.ac.uk/europepmc/annotations_api/annotationsByArticleIds
  # Should only contains the Open access articles but didn't check it
  archive_api:
    root_url: https://europepmc.org/ftp/oa/pmcid.txt.gz
  archive_file: ./data/pmcid.txt.gz
  article_query_folder: ./data/query_articles/
  article_human_folder: ./data/articles_human/
  pmcid_species_file: ./data/pmcid_species.txt
  # Used in previous script to be able to rerun the script without redl everything. Maybe still needed
  # For the new downloading script
  pmcid_human_file: ./data/pmcid_humans.txt
  db_info_articles: ./data/db_info_articles.sqlite3
  record_files: true
  xml_origin: api # can be either 'api' if connect to the api or 'files' if use dl files

search_params:
  rerun_archive: true
  query:  eLIfe AND (HAS_FT:Y AND OPEN_ACCESS:Y )
  # found using the script species_exploration.ipynb for manual exploration of the different terms
  human_terms: [human, humans, man, homo sapiens, h. sapiens, homo_sapiens]

processing_params:
  sentence_location: ./data/candidate_sentences.csv
  json_human_folder: ./data/json_humans/
  token_sentences: [man, woman, male, female, men, women, males, females, sample]
  list_article_location: ./data/exploration/list_article.csv
  list_level_location: ./data/exploration/list_levels.csv
  list_tag_location: ./data/explorationlist_tags.csv
  list_attr_val_location: ./data/exploration/list_attr_val.csv
  list_sections_location: ./data/exploration/list_sections_details.csv
  list_parent_location: ./data/exploration/list_parent_details.csv

db_params:
  table_status: status
  table_sections: sections
  table_metadata: article_metadata
 
llm_params:
  model: "./llm_models/mistral_7b_v01"
  training_set_path: ./data/training_data/final_dataset.hf
  model_outdir: ./llm_models/
  model_train_name: dev_mistral_lora
  generation_params:
    context_size: 2048
    # n_threads: 10
    # n_gpu_layers: 8
    temperature: 0
    do_sample: True
    top_p: 0.95
    top_k: 40
    max_new_tokens: 512
    repetition_penalty: 1.1
  lora_config: 
    r: 16
    target_modules: ["q_proj", "v_proj"]
    task_type: CAUSAL_LM
    lora_alpha: 32
    lora_dropout: 0.05
  
