{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fdffacc6-4fa6-4db6-b561-415092aa17cd",
   "metadata": {},
   "source": [
    "# Important resources to implement\n",
    "- [ ] To update the graph and route at the same time (Command): https://langchain-ai.github.io/langgraph/how-tos/command/\n",
    "- [ ] To get React agent and structured output in two calls: https://langchain-ai.github.io/langgraph/how-tos/react-agent-structured-output/\n",
    "- [ ] To develop react agent: https://langchain-ai.github.io/langgraph/how-tos/react-agent-from-scratch/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f1d8c11-da88-42a6-806f-5e680c9627ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import datetime\n",
    "import json\n",
    "import random\n",
    "import logging\n",
    "import os\n",
    "import re\n",
    "import ast\n",
    "import io\n",
    "import sys\n",
    "import duckdb\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from IPython.display import Image, display\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint\n",
    "\n",
    "from utils.utils import dynamic_import, load_config\n",
    "from langchain_ollama import OllamaLLM, ChatOllama\n",
    "\n",
    "from typing import Annotated, Union,Optional\n",
    "\n",
    "from typing_extensions import TypedDict, Literal\n",
    "from pydantic import BaseModel, field_validator, ValidationError, Field, model_validator\n",
    "\n",
    "# from IPython.display import Image, display\n",
    "from langgraph.graph import StateGraph, START, END, MessagesState\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage, AnyMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from langchain_core.tools import BaseTool, tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c98925d1-c7eb-4516-9f8e-fb1192e09b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_logger() -> logging.Logger:\n",
    "    \"\"\"Setup the logger configuration for consistency.\"\"\"\n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO,\n",
    "        format=\"%(asctime)s [%(levelname)s] %(name)s: %(message)s\",\n",
    "        handlers=[logging.StreamHandler()],\n",
    "    )\n",
    "    return logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "logger = setup_logger()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a02e816-3191-4ba3-82a9-7d0e1209160e",
   "metadata": {},
   "source": [
    "## Get the data from the db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50d3a83c-09ad-45e7-8382-36cd3c13e5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_from_db(conn, table_sections, pmcid):\n",
    "    \"\"\"\n",
    "    Get the already recorded pmcids from db\n",
    "    \"\"\"\n",
    "    cursor = conn.cursor()\n",
    "    query = f\"\"\"\n",
    "        SELECT abstract, SUBJECTS, METHODS\n",
    "        FROM {table_sections} \n",
    "        WHERE pmcid = ?\n",
    "    \"\"\"\n",
    "    cursor.execute(query, (pmcid,))\n",
    "    row = cursor.fetchone()\n",
    "    cursor.close()\n",
    "    if row:\n",
    "        abstract, subjects, method = row\n",
    "        return abstract, subjects, method\n",
    "    else:\n",
    "        return None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "55a8db5a-c674-4223-a1b3-51a54af0ebc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load config\n",
    "config_path = os.path.join(\"../config\", \"config.yaml\")\n",
    "config_all = load_config(config_path)\n",
    "\n",
    "# DB connection\n",
    "# # Name of the database\n",
    "DB_FILE = config_all[\"api_europepmc_params\"][\"db_info_articles\"]\n",
    "table_status = config_all[\"db_params\"][\"table_status\"]\n",
    "table_sections = config_all[\"db_params\"][\"table_sections\"]\n",
    "table_metadata = config_all[\"db_params\"][\"table_metadata\"]\n",
    "table_inference = config_all[\"db_params\"][\"table_inference\"]\n",
    "# # Using duckdb to access the sqlite file for compatibility on marenostrum\n",
    "conn = duckdb.connect(f\"../{DB_FILE}\")\n",
    "\n",
    "# List of PMCID for testing\n",
    "list_pmcids = [\n",
    "    'PMC10167034', 'PMC10191296', 'PMC10262854', 'PMC10390885', 'PMC10451945',\n",
    "    'PMC1368980',  'PMC2383879',  'PMC2693442',  'PMC3016279',  'PMC3041764',\n",
    "    'PMC3145824',  'PMC3174812',  'PMC3212907',  'PMC3219398',  'PMC3308973',\n",
    "    'PMC3446531',  'PMC3534646',  'PMC3619104',  'PMC3804564',  'PMC3909226',\n",
    "    'PMC4006427',  'PMC4023701',  'PMC4029655',  'PMC4065281',  'PMC4152203',\n",
    "    'PMC4221596',  'PMC4251014',  'PMC4344476',  'PMC4393161',  'PMC4492682',\n",
    "    'PMC4596022',  'PMC4640153',  'PMC4928460',  'PMC5040013',  'PMC5053679',\n",
    "    'PMC5076567',  'PMC5087213',  'PMC5137654',  'PMC5149569',  'PMC5253404',\n",
    "    'PMC5308745',  'PMC5425199',  'PMC5441889',  'PMC5601641',  'PMC5645380',\n",
    "    'PMC5717332',  'PMC5784259',  'PMC5839230',  'PMC5961641',  'PMC6060212',\n",
    "    'PMC6076250',  'PMC6145291',  'PMC6160275',  'PMC6248768',  'PMC6286024',\n",
    "    'PMC6730009',  'PMC6760014',  'PMC6775309',  'PMC6853912',  'PMC6858051',\n",
    "    'PMC6955584',  'PMC7007877',  'PMC7011053',  'PMC7436656',  'PMC7449478',\n",
    "    'PMC7537889',  'PMC7550220',  'PMC7657407',  'PMC7661891',  'PMC7722655',\n",
    "    'PMC7722817',  'PMC7734296',  'PMC7882770',  'PMC7903471',  'PMC7906844',\n",
    "    'PMC7956942',  'PMC8155599',  'PMC8288503',  'PMC8382172',  'PMC8456091',\n",
    "    'PMC8723790',  'PMC8752710',  'PMC8771850',  'PMC8976245',  'PMC9028212',\n",
    "    'PMC9081438',  'PMC9138181',  'PMC9305770',  'PMC9333080',  'PMC9381901',\n",
    "    'PMC9413660',  'PMC9422814',  'PMC9529122',  'PMC9537611',  'PMC9601430',\n",
    "    'PMC9616492',  'PMC9636513',  'PMC9683380',  'PMC9697589'\n",
    "]\n",
    "pmcid_method = list()\n",
    "for pmcid in list_pmcids:#[0:10]:\n",
    "    \n",
    "    abstract, subjects, method = get_text_from_db(conn, table_sections, pmcid)\n",
    "    pmcid_method.append({'pmcid': pmcid, 'abstract': abstract, 'method': method, 'subjects': subjects})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd6f2e3a-33c9-4523-aeec-00380cd2d419",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tools\n",
    "@tool\n",
    "def extract_section_tool(document: dict, section: str) -> str:\n",
    "    \"\"\"\n",
    "    Extracts a specific section (e.g., 'Abstract', 'Method', 'Result') from a single document dictionary.\n",
    "    If the section does not exist, returns an empty string.\n",
    "    \"\"\"\n",
    "    return document.get(section, \"No content available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "44c065b6-2adb-4a4f-8eaa-d1ba01925fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Instanciate LLMs\n",
    "model_name = \"llama3.2:latest\"\n",
    "#model_name = \"qwen2.5:14b\"\n",
    "#model_name = \"llama3.2:3b-instruct-fp16\"\n",
    "#model_name = \"qwen2.5:14b-instruct-q5_K_S\"\n",
    "model_name = 'phi4'\n",
    "llm = ChatOllama(model=model_name)\n",
    "llm.temperature = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d0d4c760-0f23-453a-a724-ee45e5cc0515",
   "metadata": {},
   "outputs": [],
   "source": [
    "# States\n",
    "class PrivateState(BaseModel):\n",
    "    pass\n",
    "    \n",
    "class DecisionState(BaseModel):\n",
    "    article: dict = {}\n",
    "    answer_context: dict = Field(default={}, description=\"Context of the decision process from the agent\")\n",
    "    human_subjects: bool = Field(default=False, description=\"Does the article contain information about human subjects\")\n",
    "    sex_or_sample_data: bool = Field(default=False, description=\"Does the article contains information about the sex of the subjects\")\n",
    "    multi_sample: bool = Field(default=False, description=\"Does the research involves several samples\")\n",
    "    #one_subject: bool = Field(default=False, description=\"Does the samples provides from the same subject\")   \n",
    "    multi_cohorts: bool = Field(default=False, description=\"Are there several cohorts\")\n",
    "    cohorts_overlap: bool = Field(default=False, description=\"Are some subjects present in more than one cohort\")\n",
    "    dropouts_before: bool = Field(default=False, description=\"Are there participants who drop the studies before the research started\")\n",
    "    dropouts_during: bool = Field(default=False, description=\"Are there participants who drop the studies during the research\")\n",
    "    droupouts_after: bool = Field(default=False, description=\"Are there participants who drop the studies after the research\")\n",
    "    info_text: bool = Field(default=False, description=\"Is the information contained in the text\")\n",
    "    info_table: bool = Field(default=False, description=\"Is the information contained in table\")\n",
    "\n",
    "\n",
    "class ResultResponse(BaseModel):\n",
    "    n_male: float = Field(default=np.nan, description=\"The total number of unique male reported in the paper\")\n",
    "    n_female: float = Field(default=np.nan, description=\"The total number of unique female reported in the paper\")\n",
    "    n_sample: float = Field(default=np.nan, description=\"The total number of unique participants reported in the paper\")\n",
    "\n",
    "\n",
    "class FinalResponse(DecisionState, ResultResponse):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5aabbaff-a095-427b-9b3d-c9744d239a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pydantic parsers\n",
    "from pydantic import BaseModel, Field, model_validator\n",
    "import json\n",
    "import ast\n",
    "\n",
    "class BooleanParser(BaseModel):\n",
    "    answer: bool = Field(description=\"Must be either 'True' or 'False'\")\n",
    "    \n",
    "    @model_validator(mode=\"before\")\n",
    "    @classmethod\n",
    "    def preprocess_input(cls, values: dict) -> dict:\n",
    "        raw_answer = values.get(\"answer\")\n",
    "        \n",
    "        if isinstance(raw_answer, str):\n",
    "            # Clean and convert string if necessary\n",
    "            raw_answer = cls._clean_and_convert_string(raw_answer)\n",
    "        \n",
    "        # Handle case where raw_answer is a dictionary with an 'answer' field\n",
    "        if isinstance(raw_answer, dict) and \"answer\" in raw_answer:\n",
    "            raw_answer = raw_answer[\"answer\"]\n",
    "        \n",
    "        # If it's still a string, check for valid \"true\"/\"false\" values\n",
    "        if isinstance(raw_answer, str):\n",
    "            stripped_answer = raw_answer.strip().lower()\n",
    "            if stripped_answer in (\"true\", \"false\"):\n",
    "                raw_answer = stripped_answer == \"true\"\n",
    "        \n",
    "        # If the answer is neither boolean nor string, raise an error\n",
    "        if not isinstance(raw_answer, bool):\n",
    "            raise ValueError(f\"Answer must be 'True' or 'False', got: {raw_answer}\")\n",
    "        \n",
    "        values[\"answer\"] = raw_answer\n",
    "        return values\n",
    "\n",
    "    @staticmethod\n",
    "    def _clean_and_convert_string(raw_answer: str) -> any:\n",
    "        raw_answer = raw_answer.strip(\"`\").strip()\n",
    "        \n",
    "        if raw_answer.startswith('```json') and raw_answer.endswith('```'):\n",
    "            # Remove the ```json``` markers\n",
    "            raw_answer = raw_answer[7:-3].strip()\n",
    "\n",
    "        # Replace 'True'/'False' to lowercase for uniformity\n",
    "        raw_answer = raw_answer.replace(\"True\", \"true\").replace(\"False\", \"false\")\n",
    "        \n",
    "        try:\n",
    "            # Try to parse as JSON\n",
    "            raw_answer = json.loads(raw_answer)\n",
    "        except json.JSONDecodeError:\n",
    "            try:\n",
    "                # Try to evaluate as a Python literal\n",
    "                raw_answer = ast.literal_eval(raw_answer)\n",
    "            except (ValueError, SyntaxError):\n",
    "                print(f\"Failed to parse raw_answer: {raw_answer}\")\n",
    "                pass\n",
    "        \n",
    "        return raw_answer\n",
    "    \n",
    "    @model_validator(mode=\"after\")\n",
    "    @classmethod\n",
    "    def validate_answer(cls, model: \"BooleanParser\") -> \"BooleanParser\":\n",
    "        if not isinstance(model.answer, bool):\n",
    "            raise ValueError(f\"Answer must be a boolean (True or False), got: {model.answer}\")\n",
    "        return model\n",
    "    \n",
    "    \n",
    "class ContextParser(BooleanParser):\n",
    "    context: str = Field(default='', description=\"Relevant sentences or data supporting the decision\")\n",
    "\n",
    "    @model_validator(mode=\"before\")\n",
    "    @classmethod\n",
    "    def preprocess_input(cls, values: dict) -> dict:\n",
    "        # First, handle BooleanParser preprocessing\n",
    "        values = super().preprocess_input(values)\n",
    "\n",
    "        # Additional preprocessing for context\n",
    "        raw_context = values.get(\"context\", \"\")\n",
    "        if isinstance(raw_context, str):\n",
    "            values[\"context\"] = raw_context.strip()\n",
    "\n",
    "        return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "004682f0-2a2e-42f0-9fad-1fcca9033d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nodes\n",
    "def human_subject_decision(state: DecisionState) -> dict:\n",
    "    \"\"\"\n",
    "    Determines if the article discusses human subjects by querying different sections of a single document.\n",
    "    \"\"\"\n",
    "    print('Inside the human_subject_decision node')\n",
    "    \n",
    "    system_message = \"\"\"\n",
    "    You are a helpful assistant analyzing a scientific article. \n",
    "    You can call tools to extract specific sections of the document.\n",
    "    \"\"\"\n",
    "    user_message = \"\"\"\n",
    "    Your task is to determine if the article consider human subjects for a study. \n",
    "    Analyze the following section: {section_header} of the document:\n",
    "    {section_content}\n",
    "    Answer as follows:\n",
    "    - 'True': The document mentions human subjects.\n",
    "    - 'False': The document does not mention human subjects, or there is not enough information to take an informed decision\n",
    "\n",
    "    Important: You need to answer the question following this format instructions:\\n\\n{format_instructions}\n",
    "    Fully respect the format_instruction and don't answer anything more than what it is asked\n",
    "    \"\"\"\n",
    "  \n",
    "    parser = PydanticOutputParser(pydantic_object=BooleanParser)\n",
    "    \n",
    "    for section in state.article:\n",
    "        section_content = state.article[section]\n",
    "\n",
    "        if section.lower() == 'pmcid'  or section_content is None:\n",
    "            continue  # Skip if the section is not available\n",
    "        # Call the tool to extract the section\n",
    "        print(f\"Section: {section} - Nbr of word {len(section_content)}\")\n",
    "\n",
    "        chat_prompt = ChatPromptTemplate.from_messages([(\"system\", system_message), (\"user\", user_message)])\n",
    "\n",
    "        prompt_messages = chat_prompt.format_messages(section_header=section, section_content=section_content, format_instructions=parser.get_format_instructions())\n",
    "        response = llm.invoke(prompt_messages)\n",
    "#           print(response)\n",
    "\n",
    "        try:\n",
    "            # print(f\"The full answer: {response}\")\n",
    "            print(f\"The response content: {response.content}\")\n",
    "            parsed_response = parser.invoke(response.content)\n",
    "            #print(f\"Parsed response: {parsed_response.answer}\")\n",
    "\n",
    "            if parsed_response.answer == True:  # If 'True' is found, return immediately\n",
    "                return {\"human_subjects\": parsed_response.answer}\n",
    "        except ValueError as e:\n",
    "            print(f\"Error in human node: {response}\")\n",
    "            raise ValueError(\"Validation failed for model: \" + str(e))\n",
    "\n",
    "    return {\"human_subjects\": False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d28e013e-242b-4d9d-a2ed-74e023f214f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contain_sex_or_sample(state: DecisionState):\n",
    "    \"\"\"\n",
    "    Determines if the article contains information about sex. \n",
    "    \"\"\"\n",
    "    print('Inside the contain_sex_or_sample node')\n",
    "    \n",
    "    system_message = \"\"\"\n",
    "    You are a helpful assistant analyzing a scientific article. \n",
    "    \"\"\"\n",
    "    user_message = \"\"\"\n",
    "    The article includes experiment involving human subjects. \n",
    "    Your task is to determine the presence of information about sex or gender in the section. \n",
    "    \n",
    "    Here, 4 non-exhaustive examples of what it may look like:\n",
    "    #######\n",
    "\n",
    "    Example 1: Twenty-seven subjects (age range 19–58, ten female) diagnosed with an ASD (see Table 1) participated in this study. \n",
    "    ASD diagnosis was determined using the Autism Diagnostic Observation Schedule (ADOS), \n",
    "    Module 4. Additionally, fifteen typical adults recruited from the local community served as behavioral controls (age range 19–59) and only participated in the face discrimination experiment described in Section 2.3.\n",
    "\n",
    "    Example 2: The strategy was to select contrasting groups including the 200 women and men (100 each) with the highest EE scores, 200 with medium EE and 200 with the lowest EE scores. \n",
    "    After plotting the EE scores for women and men separately, the cutoff was set around the highest quartile, the median and around the lowest quartile. \n",
    "    The selection procedures yielded a sample of 720 individuals. Some of them enrolled in a parallel study were excluded. \n",
    "    As a result, the final sample included 687 individuals consisting of 143 women and 127 men with low EE scores, 118 women and 110 men with medium EE scores and 119 women and 103 men with high EE scores.\n",
    "\n",
    "    Example 3: Table 1Subject characteristics at baseline1VLCARBVLFHUFmales/females4/205/173/18BMI kg/m232.5 \\u00b1 3.132.6 \\u00b1 4.033.4 \\u00b1 3.6AGE y48.4 \\u00b1 8.050.7 \\u00b1 10.346.1 \\u00b1 9.5Total Cholesterol mmol/L5.8 \\u00b1 1.05.6 \\u00b1 1.16.0 \\u00b1 1.1LDL-C mmol/L3.8 \\u00b1 0.83.6 \\u00b1 1.14.0 \\u00b1 1.1HDL-C mmol/L1.2 \\u00b1 0.21.3 \\u00b1 0.31.2 \\u00b1 0.2Triacylglycerols mmol/L1.8 \\u00b1 0.91.5 \\u00b1 0.61.6 \\u00b1 0.51 Data are Mean \\u00b1 SD. VLCARB = very low carbohydrate diet (n = 24) VLF = very low fat diet (n = 22) HUF = high unsaturated fat (n = 21)\n",
    "\n",
    "    Example 4:Fifteen healthy human volunteers took part in the study. They were screened for normal stereoacuity before being invited to participate. \n",
    "    Two were later excluded because of poor binocular fusion during scanning. Therefore, data from 13 participants (10 female; mean age 27 yr) were included in the analysis.\n",
    "    ########\n",
    "    \n",
    "    Do that analyse for the following section {section_header} of the document:\n",
    "    \n",
    "    {section_content}\n",
    "\n",
    "    Answer as follows:\n",
    "    - 'True': The document contains information to know if some participants are males or females or if the information about the gender is given. Even if only one gender or sex can be inferred, answer True\n",
    "    - 'False': The document does not contain information about the sex or the gender of the participants.\n",
    "    Additionally, if the answer is 'True', include the relevant sentences or table excerpts from the section that support your decision in the 'context' field\n",
    "    If the document is empty, just answer False, I will provide another section to try again.\n",
    "    \n",
    "    Important: You need to answer the question following this format instructions:\\n\\n{format_instructions}\n",
    "    Fully respect the format_instruction and don't answer anything more than what it is asked\n",
    "    \"\"\"\n",
    "  \n",
    "    parser = PydanticOutputParser(pydantic_object=ContextParser)\n",
    "\n",
    "    for section in state.article:\n",
    "        section_content = state.article[section]\n",
    "\n",
    "        if section.lower() == 'pmcid'  or section_content is None:\n",
    "            continue  # Skip if the section is not available\n",
    "        # Call the tool to extract the section\n",
    "        print(f\"Section: {section} - Nbr of word {len(section_content)}\")\n",
    "\n",
    "        chat_prompt = ChatPromptTemplate.from_messages([(\"system\", system_message), (\"user\", user_message)])\n",
    "\n",
    "        prompt_messages = chat_prompt.format_messages(section_header=section, section_content=section_content, format_instructions=parser.get_format_instructions())\n",
    "        response = llm.invoke(prompt_messages)\n",
    "#           print(response)\n",
    "\n",
    "        try:\n",
    "            # print(f\"The full answer: {response}\")\n",
    "            \n",
    "            print(f\"The response content: {response.content}\")\n",
    "            parsed_response = parser.invoke(response.content)\n",
    "            #print(f\"Parsed response: {parsed_response.answer}\")\n",
    "\n",
    "            if parsed_response.answer == True:  # If 'True' is found, return immediately\n",
    "                return {\"sex_or_sample_data\": parsed_response.answer}\n",
    "        except ValueError as e:\n",
    "            print(f\"Error in human node: {response}\")\n",
    "            raise ValueError(\"Validation failed for model: \" + str(e))\n",
    "\n",
    "    return {\"sex_or_sample_data\": False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f88dc4b8-c416-4ce9-a7d2-0936f2a3ea6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_samples(state: DecisionState) -> str:\n",
    "    \"\"\"\n",
    "    Determines if the article mentions sample from multi individuals, or if there are several participants\n",
    "    \"\"\"\n",
    "    print('Inside the multi_samples node')\n",
    "\n",
    "    system_message = \"\"\"\n",
    "    You are a helpful assistant analyzing a scientific article. \n",
    "    You can call tools to extract specific sections of the document.\n",
    "    \"\"\"\n",
    "    user_message = \"\"\"\n",
    "    Your task is to determine the presence of information about sex or gender in the following study.\n",
    "    Analyze the following section: {section_header} of the document:\n",
    "    {section_content}\n",
    "    Answer as follows:\n",
    "    - 'True': If the experience report to have more than one human subject or participant\n",
    "    - 'False':  If it is not involving several humans or subjects and or several lines of tissues, cells, etc or there is not enough information to take an informed decision\n",
    "    Additionally, if the answer is 'True', include the relevant sentences or table excerpts from the section that support your decision in the 'context' field.\n",
    "    Important: You need to answer the question following this format instructions:\\n\\n{format_instructions}\n",
    "    Fully respect the format_instruction and don't answer anything more than what it is asked\n",
    "   \"\"\"\n",
    "    parser = PydanticOutputParser(pydantic_object=ContextParser)\n",
    "\n",
    "    for section in state.article:\n",
    "        section_content = state.article[section]\n",
    "\n",
    "        if section.lower() == 'pmcid'  or section_content is None:\n",
    "            continue  # Skip if the section is not available\n",
    "        # Call the tool to extract the section\n",
    "        print(f\"Section: {section} - Nbr of word {len(section_content)}\")\n",
    "\n",
    "        chat_prompt = ChatPromptTemplate.from_messages([(\"system\", system_message), (\"user\", user_message)])\n",
    "\n",
    "        prompt_messages = chat_prompt.format_messages(section_header=section, section_content=section_content, format_instructions=parser.get_format_instructions())\n",
    "        response = llm.invoke(prompt_messages)\n",
    "#           print(response)\n",
    "\n",
    "        try:\n",
    "            # print(f\"The full answer: {response}\")\n",
    "            \n",
    "            print(f\"The response content: {response.content}\")\n",
    "            parsed_response = parser.invoke(response.content)\n",
    "            #print(f\"Parsed response: {parsed_response.answer}\")\n",
    "\n",
    "            if parsed_response.answer == True:  # If 'True' is found, return immediately\n",
    "                return {\"multi_sample\": parsed_response.answer}\n",
    "        except ValueError as e:\n",
    "            print(f\"Error in human node: {response}\")\n",
    "            raise ValueError(\"Validation failed for model: \" + str(e))\n",
    "\n",
    "    return {\"multi_sample\": False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "bc01a81e-8bf6-4c44-8988-ae4bf8ed38b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_cohort(state: DecisionState) -> str:\n",
    "    \"\"\"\n",
    "    Determines if there are several cohorts or studies in the same article.\n",
    "    \"\"\"\n",
    "    print('Inside the multi_cohort node')\n",
    "\n",
    "    system_message = \"\"\"\n",
    "    You are a helpful assistant analyzing a scientific article. \n",
    "    You can call tools to extract specific sections of the document.\n",
    "    \"\"\"\n",
    "    user_message = \"\"\"\n",
    "    Your task is to understand if the reported experience are about several human subjects or about only one participant. \n",
    "    \\t If the experience report to have more than one human subject or participant, answer 'True'.\n",
    "    \\t If it is not involving several humans or subjects and or several lines of tissues, cells, etc, answer 'False'.\n",
    "    Additionally, if the answer is 'True', include the relevant sentences or table excerpts from the section that support your decision in the 'context' field.\n",
    "\n",
    "    Important: You need to answer the question following this format instructions:\\n\\n{format_instructions}\"\"\"\n",
    "\n",
    "    parser = PydanticOutputParser(pydantic_object=ContextParser)\n",
    "    \n",
    "    for section in state.article:\n",
    "\n",
    "        # Call the tool to extract the section\n",
    "        section_content = state.article[section]\n",
    "        if section_content == \"No content available.\":\n",
    "            continue  # Skip if the section is not available\n",
    "        \n",
    "    \n",
    "        chat_prompt = ChatPromptTemplate.from_messages([(\"system\", system_message), (\"user\", user_message)])\n",
    "\n",
    "        prompt_messages = chat_prompt.format_messages(section_header=section, section_content=section_content, format_instructions=parser.get_format_instructions())\n",
    "        response = llm.invoke(prompt_messages)\n",
    "        try:\n",
    "            parsed_response = parser.invoke(response.content.strip())\n",
    "            #print(f\"Parsed response: {parsed_response.answer}\")\n",
    "            if parsed_response.answer == True:  # If 'True' is found, return immediately\n",
    "                context = state.answer_context\n",
    "                context['multi_cohort'] = {section: parsed_response.context }\n",
    "\n",
    "                return {\"multi_cohort\": parsed_response.answer,\n",
    "                        \"answer_context\": context}\n",
    "        except ValueError as e:\n",
    "            raise ValueError(\"Validation failed for model: \" + str(e))\n",
    "\n",
    "    return {\"multi_cohort\": parsed_response.answer}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9900a0a1-abe5-495a-9b2a-58617e8ee104",
   "metadata": {},
   "outputs": [],
   "source": [
    "def participants_dropout(state: DecisionState) -> str:\n",
    "    \"\"\"\n",
    "    Determines if there are several cohorts or studies in the same article.\n",
    "    \"\"\"\n",
    "    system_message = \"You are a helpful assistant that needs to extract information from a scientific article from pubmed and follow the instruction given by the user\"\n",
    "    user_message = \"\"\"Here is a scientific article. It contains one study or one experience about human subjects humans subject:\\n\\n{article}\n",
    "    In study it can happens that some participants are selected before the survey but eventually are removed for various reasons. \n",
    "    It can be also the case that participants are dropping out during the study or even after the study is done. \n",
    "    Your task is to analyse the text provided which details the method section. In there you need to figure out if there is such case of dropout.\n",
    "    If partipants (or subjects) are removed before the ss\n",
    "    \\t If the experience report to have more than one human subject or participant, answer 'True'.\n",
    "    \\t If it is not involving several humans or subjects and or several lines of tissues, cells, etc, answer 'False'.\n",
    "    Important: You need to answer the question following this format instructions:\\n\\n{format_instructions}\"\"\"\n",
    "\n",
    "    parser = PydanticOutputParser(pydantic_object=BooleanParser)\n",
    "    \n",
    "    chat_prompt = ChatPromptTemplate.from_messages([(\"system\", system_message), (\"user\", user_message)])\n",
    "\n",
    "    prompt_messages = chat_prompt.format_messages(article=state.article, format_instructions=parser.get_format_instructions())\n",
    "\n",
    "    response = llm.invoke(prompt_messages)\n",
    "    # print(f\"Straight response: {response}\")\n",
    "\n",
    "    try:\n",
    "        # print(\"Raw response content:\", response.content.strip())\n",
    "        parsed_response = parser.invoke(response.content.strip())\n",
    "        # print(\"Parsed response:\", parsed_response)  # Debugging print\n",
    "    except ValueError as e:\n",
    "        raise ValueError(\"Validation failed for model: \" + str(e))\n",
    "\n",
    "    return {\"multi_cohort\": parsed_response.answer}\n",
    "\n",
    "\n",
    "def participant_dropout_tools():\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f6112972-5def-4408-a35d-909c2c664e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_information(state: DecisionState) -> dict:\n",
    "    \"\"\"\n",
    "    Extracts numerical data (e.g., number of males, females, total participants).\n",
    "    \"\"\"\n",
    "    if state.multi_cohort == True:\n",
    "        adding_message = 'There are several cohort in the article'\n",
    "    else:\n",
    "        adding_message = ''\n",
    "    system_message = \"You are a helpful assistant that needs to extract information from a scientific article from pubmed and follow the instruction given by the user\"\n",
    "    user_message = \"\"\"Here is a scientific article. It contains experience and or survey about humans subject :\\n\\n{article}\n",
    "    Your task is to understand if the reported experience are about several human subjects or about only one participant. \n",
    "    \\t If the experience report to have more than one human subject or participant, answer 'True'.\n",
    "    \\t If it is not involving several humans or subjects and or several lines of tissues, cells, etc, answer 'False'.\n",
    "    Important: You need to answer the question following this format instructions:\\n\\n{format_instructions}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3d91dca4-35ec-4901-b7bb-9d523acdb758",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_numbers(state: DecisionState) -> dict:\n",
    "    \"\"\"\n",
    "    Extracts numerical data (e.g., number of males, females, total participants).\n",
    "    \"\"\"\n",
    "    result_response = ResultResponse(\n",
    "        n_male=50, \n",
    "        n_female=60, \n",
    "        n_sample=110\n",
    "    )\n",
    "    return {\n",
    "        \"n_male\": result_response.n_male,\n",
    "        \"n_female\": result_response.n_female,\n",
    "        \"n_sample\": result_response.n_sample,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "56c4a7d3-a2fa-44f7-9f71-2d27bf121a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def human_decision_router(state: DecisionState) -> str:\n",
    "    print(f\"In human_decision_router: {state.human_subjects}\")\n",
    "    if state.human_subjects is True:\n",
    "        return \"contain_sex_or_sample\"\n",
    "    elif state.human_subjects is False:\n",
    "        return END\n",
    "    else:\n",
    "        raise\n",
    "\n",
    "def contain_sex_router(state: DecisionState) -> str:\n",
    "    print(f\"In contain_sex_router: {state.sex_or_sample_data}\")\n",
    "    if state.sex_or_sample_data == True:\n",
    "        return \"multi_samples\"\n",
    "    elif state.sex_or_sample_data == False:\n",
    "        return END\n",
    "\n",
    "def multi_sample_router(state: DecisionState) -> str:\n",
    "    print(f\"In multi_sample_router: {state.multi_sample}\")\n",
    "    if state.multi_sample == \"True\":\n",
    "        return \"multi_cohort\"\n",
    "    elif state.multi_sample == \"False\":\n",
    "        return END\n",
    "\n",
    "def multi_cohort_router(state: DecisionState) -> str:\n",
    "    print(f\"In multi_sample_router: {state.multi_sample}\")\n",
    "    if state.multi_cohort == \"True\":\n",
    "        return END\n",
    "    elif state.multi_cohort == \"False\":\n",
    "        return \"participants_dropout\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "cab9a0bf-b063-496d-9955-8686484c3002",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "graph = StateGraph(DecisionState, output=FinalResponse)\n",
    "\n",
    "graph.add_node(\"human_subject_decision\", human_subject_decision)\n",
    "graph.add_node(\"contain_sex_or_sample\", contain_sex_or_sample)\n",
    "graph.add_node(\"multi_samples\", multi_samples)\n",
    "graph.add_node(\"multi_cohort\", multi_cohort)\n",
    "#graph.add_node(\"participants_dropout\", participants_dropout)\n",
    "\n",
    "\n",
    "#graph.add_node(\"calculate_numbers\", calculate_numbers)\n",
    "\n",
    "graph.add_edge(START, \"human_subject_decision\")\n",
    "graph.add_conditional_edges(\"human_subject_decision\", human_decision_router,  path_map=[\"contain_sex_or_sample\", END])\n",
    "graph.add_conditional_edges(\"contain_sex_or_sample\", contain_sex_router, path_map=[\"multi_samples\", END])\n",
    "graph.add_conditional_edges(\"multi_samples\", multi_sample_router, path_map=[\"multi_cohort\", END])\n",
    "#graph.add_conditional_edges(\"multi_cohort\", multi_cohort_router, path_map=[\"participants_dropout\", END])\n",
    "\n",
    "#graph.add_edge(\"participants_dropout\", \"calculate_numbers\")\n",
    "#graph.add_edge(\"calculate_numbers\", END)\n",
    "graph.add_edge('multi_cohort', END)\n",
    "graph = graph.compile()\n",
    "display(Image(graph.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "79037651-1399-455b-81c0-83c2bd5460ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inside the human_subject_decision node\n",
      "Section: method - Nbr of word 8763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The response content: ```json\n",
      "{\n",
      "  \"answer\": true\n",
      "}\n",
      "```\n",
      "In human_decision_router: True\n",
      "Inside the contain_sex_or_sample node\n",
      "Section: method - Nbr of word 8763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The response content: ```json\n",
      "{\n",
      "  \"answer\": false,\n",
      "  \"context\": \"\"\n",
      "}\n",
      "```\n",
      "In contain_sex_router: False\n",
      "Final answer: {'answer_context': {}, 'human_subjects': True, 'sex_or_sample_data': False, 'multi_sample': False, 'multi_cohorts': False, 'cohorts_overlap': False, 'dropouts_before': False, 'dropouts_during': False, 'droupouts_after': False, 'info_text': False, 'info_table': False}\n",
      "Inside the human_subject_decision node\n",
      "Section: method - Nbr of word 14076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The response content: ```json\n",
      "{\n",
      "  \"answer\": true\n",
      "}\n",
      "``` \n",
      "\n",
      "The document mentions human subjects as it discusses a study involving Medicare beneficiaries, which are individuals. The study includes data on incident neurodegenerative disease among these individuals, indicating that the research involves human participants. Therefore, the answer is 'True'.\n",
      "In human_decision_router: True\n",
      "Inside the contain_sex_or_sample node\n",
      "Section: method - Nbr of word 14076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The response content: ```json\n",
      "{\n",
      "  \"answer\": true,\n",
      "  \"context\": \"We also censored individuals if and when they developed atypical parkinsonism, developed dementia with Lewy bodies, or enrolled in Part C coverage. We used age as the time scale to account for age and then included all other covariates as independent variables in the model.\"\n",
      "}\n",
      "```\n",
      "In contain_sex_router: True\n",
      "Inside the multi_samples node\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In multi_sample_router: True\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[77], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m article \u001b[38;5;129;01min\u001b[39;00m pmcid_method:\n\u001b[1;32m      2\u001b[0m     initial_state \u001b[38;5;241m=\u001b[39m DecisionState(article\u001b[38;5;241m=\u001b[39marticle)  \u001b[38;5;66;03m# Call the initial_state like that otherwise DecisionState is not populated with default values\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43minitial_state\u001b[49m\u001b[43m)\u001b[49m  \n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124marticle\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinal answer: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/git/pro/bsc/biohackathon-2022-project-24/venv/lib/python3.12/site-packages/langgraph/pregel/__init__.py:1927\u001b[0m, in \u001b[0;36mPregel.invoke\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, **kwargs)\u001b[0m\n\u001b[1;32m   1925\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1926\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m-> 1927\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1928\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1929\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1930\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1931\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1932\u001b[0m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1933\u001b[0m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1934\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdebug\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdebug\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1935\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1936\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1937\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalues\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1938\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlatest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\n",
      "File \u001b[0;32m~/git/pro/bsc/biohackathon-2022-project-24/venv/lib/python3.12/site-packages/langgraph/pregel/__init__.py:1647\u001b[0m, in \u001b[0;36mPregel.stream\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[0m\n\u001b[1;32m   1641\u001b[0m     \u001b[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[1;32m   1642\u001b[0m     \u001b[38;5;66;03m# computation proceeds in steps, while there are channel updates\u001b[39;00m\n\u001b[1;32m   1643\u001b[0m     \u001b[38;5;66;03m# channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[1;32m   1644\u001b[0m     \u001b[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[1;32m   1645\u001b[0m     \u001b[38;5;66;03m# with channel updates applied only at the transition between steps\u001b[39;00m\n\u001b[1;32m   1646\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mtick(input_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_channels):\n\u001b[0;32m-> 1647\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1648\u001b[0m \u001b[43m            \u001b[49m\u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtasks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1649\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1650\u001b[0m \u001b[43m            \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1651\u001b[0m \u001b[43m            \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1652\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1653\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[1;32m   1654\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1655\u001b[0m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
      "File \u001b[0;32m~/git/pro/bsc/biohackathon-2022-project-24/venv/lib/python3.12/site-packages/langgraph/pregel/runner.py:104\u001b[0m, in \u001b[0;36mPregelRunner.tick\u001b[0;34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[0m\n\u001b[1;32m    102\u001b[0m t \u001b[38;5;241m=\u001b[39m tasks[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 104\u001b[0m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwriter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwriter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/git/pro/bsc/biohackathon-2022-project-24/venv/lib/python3.12/site-packages/langgraph/pregel/retry.py:40\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[0;34m(task, retry_policy, writer)\u001b[0m\n\u001b[1;32m     38\u001b[0m task\u001b[38;5;241m.\u001b[39mwrites\u001b[38;5;241m.\u001b[39mclear()\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# if successful, end\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/git/pro/bsc/biohackathon-2022-project-24/venv/lib/python3.12/site-packages/langgraph/utils/runnable.py:412\u001b[0m, in \u001b[0;36mRunnableSeq.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    410\u001b[0m             \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    411\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 412\u001b[0m             \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[1;32m    414\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/git/pro/bsc/biohackathon-2022-project-24/venv/lib/python3.12/site-packages/langgraph/utils/runnable.py:184\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    183\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, config)\n\u001b[0;32m--> 184\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurse:\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[0;32m~/git/pro/bsc/biohackathon-2022-project-24/venv/lib/python3.12/site-packages/langgraph/graph/graph.py:96\u001b[0m, in \u001b[0;36mBranch._route\u001b[0;34m(self, input, config, reader, writer)\u001b[0m\n\u001b[1;32m     94\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\n\u001b[1;32m     95\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39minvoke(value, config)\n\u001b[0;32m---> 96\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_finish\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/git/pro/bsc/biohackathon-2022-project-24/venv/lib/python3.12/site-packages/langgraph/graph/graph.py:132\u001b[0m, in \u001b[0;36mBranch._finish\u001b[0;34m(self, writer, input, result, config)\u001b[0m\n\u001b[1;32m    129\u001b[0m     result \u001b[38;5;241m=\u001b[39m [result]\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mends:\n\u001b[1;32m    131\u001b[0m     destinations: Sequence[Union[Send, \u001b[38;5;28mstr\u001b[39m]] \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m--> 132\u001b[0m         r \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(r, Send) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mends\u001b[49m\u001b[43m[\u001b[49m\u001b[43mr\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m result\n\u001b[1;32m    133\u001b[0m     ]\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    135\u001b[0m     destinations \u001b[38;5;241m=\u001b[39m cast(Sequence[Union[Send, \u001b[38;5;28mstr\u001b[39m]], result)\n",
      "\u001b[0;31mKeyError\u001b[0m: None"
     ]
    }
   ],
   "source": [
    "for article in pmcid_method:\n",
    "    initial_state = DecisionState(article=article)  # Call the initial_state like that otherwise DecisionState is not populated with default values\n",
    "    result = graph.invoke(initial_state)  \n",
    "    del result['article']\n",
    "    print(f\"Final answer: {result}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0fa886-609a-413f-aa35-7371290264c8",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb3594f-3726-4b1e-8325-c3fb83d5b35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example inputs to validate\n",
    "weird_string_test = '```json\\n{\\n  \"answer\": True\\n}\\n```'\n",
    "\n",
    "inputs = [\n",
    "    {\"answer\": \"False\"},                       # String \"False\"\n",
    "    {\"answer\": \"True\"},                        # String \"True\"\n",
    "    {\"answer\": \"true\"},                        # Case-insensitive \"true\"\n",
    "    {\"answer\": \"false\"},                       # Case-insensitive \"false\"\n",
    "    {\"answer\": '{\"answer\": \"True\"}'},          # JSON with nested \"True\" as string\n",
    "    {\"answer\": '{\"answer\": true}'},            # JSON with boolean true\n",
    "    {\"answer\": \"True   \"},                     # String with extra whitespace\n",
    "    {\"answer\": \"False   \"},                    # String with extra whitespace\n",
    "    {\"answer\": \"Not a boolean\"},               # Invalid string\n",
    "    {\"answer\": '{\"answer\": \"Not a boolean\"}'}, # Nested invalid value\n",
    "    {\"answer\": '{\"answer\": false}'},           # Nested valid boolean false\n",
    "    {\"answer\": True},                          # Python-style True\n",
    "    {\"answer\": False},                         # Python-style False\n",
    "    {\"answer\": None},                          # None input\n",
    "    {\"answer\": weird_string_test},             # Weird string with JSON-like content\n",
    "]\n",
    "\n",
    "# Test each input\n",
    "for i, input_data in enumerate(inputs):\n",
    "    try:\n",
    "        print(f\"Testing input {i + 1}: {input_data}\")\n",
    "        result = BooleanParser(**input_data)\n",
    "        print(f\"Test case {i+1}: {input_data} -> Parsed: {result}\")\n",
    "    except ValueError as e:\n",
    "        print(f\"Test case {i+1}: {input_data} -> Error: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Test case {i+1}: {input_data} -> Unexpected Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fad2a06-e693-4001-a236-89ef3cce6bff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
