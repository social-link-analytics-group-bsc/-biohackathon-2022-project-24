{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fdffacc6-4fa6-4db6-b561-415092aa17cd",
   "metadata": {},
   "source": [
    "# Important resources to implement\n",
    "- [ ] To update the graph and route at the same time (Command): https://langchain-ai.github.io/langgraph/how-tos/command/\n",
    "- [ ] To get React agent and structured output in two calls: https://langchain-ai.github.io/langgraph/how-tos/react-agent-structured-output/\n",
    "- [ ] To develop react agent: https://langchain-ai.github.io/langgraph/how-tos/react-agent-from-scratch/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1d8c11-da88-42a6-806f-5e680c9627ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import datetime\n",
    "import json\n",
    "import random\n",
    "import logging\n",
    "import os\n",
    "import re\n",
    "import ast\n",
    "import io\n",
    "import sys\n",
    "import duckdb\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from IPython.display import Image, display\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint\n",
    "\n",
    "from utils.utils import dynamic_import, load_config\n",
    "from langchain_ollama import OllamaLLM, ChatOllama\n",
    "\n",
    "from typing import Annotated, Union,Optional\n",
    "\n",
    "from typing_extensions import TypedDict, Literal\n",
    "from pydantic import BaseModel, field_validator, ValidationError, Field, model_validator\n",
    "\n",
    "# from IPython.display import Image, display\n",
    "from langgraph.graph import StateGraph, START, END, MessagesState\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage, AnyMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from langchain_core.tools import BaseTool, tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98925d1-c7eb-4516-9f8e-fb1192e09b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_logger() -> logging.Logger:\n",
    "    \"\"\"Setup the logger configuration for consistency.\"\"\"\n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO,\n",
    "        format=\"%(asctime)s [%(levelname)s] %(name)s: %(message)s\",\n",
    "        handlers=[logging.StreamHandler()],\n",
    "    )\n",
    "    return logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "logger = setup_logger()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a02e816-3191-4ba3-82a9-7d0e1209160e",
   "metadata": {},
   "source": [
    "## Get the data from the db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d3a83c-09ad-45e7-8382-36cd3c13e5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_from_db(conn, table_sections, pmcid):\n",
    "    \"\"\"\n",
    "    Get the already recorded pmcids from db\n",
    "    \"\"\"\n",
    "    cursor = conn.cursor()\n",
    "    query = f\"\"\"\n",
    "        SELECT abstract, SUBJECTS, METHODS\n",
    "        FROM {table_sections} \n",
    "        WHERE pmcid = ?\n",
    "    \"\"\"\n",
    "    cursor.execute(query, (pmcid,))\n",
    "    row = cursor.fetchone()\n",
    "    cursor.close()\n",
    "    if row:\n",
    "        abstract, subjects, method = row\n",
    "        return abstract, subjects, method\n",
    "    else:\n",
    "        return None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a8db5a-c674-4223-a1b3-51a54af0ebc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load config\n",
    "config_path = os.path.join(\"../config\", \"config.yaml\")\n",
    "config_all = load_config(config_path)\n",
    "\n",
    "# DB connection\n",
    "# # Name of the database\n",
    "DB_FILE = config_all[\"api_europepmc_params\"][\"db_info_articles\"]\n",
    "table_status = config_all[\"db_params\"][\"table_status\"]\n",
    "table_sections = config_all[\"db_params\"][\"table_sections\"]\n",
    "table_metadata = config_all[\"db_params\"][\"table_metadata\"]\n",
    "table_inference = config_all[\"db_params\"][\"table_inference\"]\n",
    "# # Using duckdb to access the sqlite file for compatibility on marenostrum\n",
    "conn = duckdb.connect(f\"../{DB_FILE}\")\n",
    "\n",
    "# List of PMCID for testing\n",
    "list_pmcids = [\n",
    "    'PMC10167034', 'PMC10191296', 'PMC10262854', 'PMC10390885', 'PMC10451945',\n",
    "    'PMC1368980',  'PMC2383879',  'PMC2693442',  'PMC3016279',  'PMC3041764',\n",
    "    'PMC3145824',  'PMC3174812',  'PMC3212907',  'PMC3219398',  'PMC3308973',\n",
    "    'PMC3446531',  'PMC3534646',  'PMC3619104',  'PMC3804564',  'PMC3909226',\n",
    "    'PMC4006427',  'PMC4023701',  'PMC4029655',  'PMC4065281',  'PMC4152203',\n",
    "    'PMC4221596',  'PMC4251014',  'PMC4344476',  'PMC4393161',  'PMC4492682',\n",
    "    'PMC4596022',  'PMC4640153',  'PMC4928460',  'PMC5040013',  'PMC5053679',\n",
    "    'PMC5076567',  'PMC5087213',  'PMC5137654',  'PMC5149569',  'PMC5253404',\n",
    "    'PMC5308745',  'PMC5425199',  'PMC5441889',  'PMC5601641',  'PMC5645380',\n",
    "    'PMC5717332',  'PMC5784259',  'PMC5839230',  'PMC5961641',  'PMC6060212',\n",
    "    'PMC6076250',  'PMC6145291',  'PMC6160275',  'PMC6248768',  'PMC6286024',\n",
    "    'PMC6730009',  'PMC6760014',  'PMC6775309',  'PMC6853912',  'PMC6858051',\n",
    "    'PMC6955584',  'PMC7007877',  'PMC7011053',  'PMC7436656',  'PMC7449478',\n",
    "    'PMC7537889',  'PMC7550220',  'PMC7657407',  'PMC7661891',  'PMC7722655',\n",
    "    'PMC7722817',  'PMC7734296',  'PMC7882770',  'PMC7903471',  'PMC7906844',\n",
    "    'PMC7956942',  'PMC8155599',  'PMC8288503',  'PMC8382172',  'PMC8456091',\n",
    "    'PMC8723790',  'PMC8752710',  'PMC8771850',  'PMC8976245',  'PMC9028212',\n",
    "    'PMC9081438',  'PMC9138181',  'PMC9305770',  'PMC9333080',  'PMC9381901',\n",
    "    'PMC9413660',  'PMC9422814',  'PMC9529122',  'PMC9537611',  'PMC9601430',\n",
    "    'PMC9616492',  'PMC9636513',  'PMC9683380',  'PMC9697589'\n",
    "]\n",
    "pmcid_method = list()\n",
    "for pmcid in list_pmcids:#[0:10]:\n",
    "    \n",
    "    abstract, subjects, method = get_text_from_db(conn, table_sections, pmcid)\n",
    "    pmcid_method.append({'pmcid': pmcid, 'abstract': abstract, 'method': method, 'subjects': subjects})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6f2e3a-33c9-4523-aeec-00380cd2d419",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tools\n",
    "@tool\n",
    "def extract_section_tool(document: dict, section: str) -> str:\n",
    "    \"\"\"\n",
    "    Extracts a specific section (e.g., 'Abstract', 'Method', 'Result') from a single document dictionary.\n",
    "    If the section does not exist, returns an empty string.\n",
    "    \"\"\"\n",
    "    return document.get(section, \"No content available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c065b6-2adb-4a4f-8eaa-d1ba01925fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Instanciate LLMs\n",
    "model_name = \"llama3.2:latest\"\n",
    "#model_name = \"qwen2.5:14b\"\n",
    "#model_name = \"llama3.2:3b-instruct-fp16\"\n",
    "#model_name = \"qwen2.5:14b-instruct-q5_K_S\"\n",
    "model_name = 'phi4'\n",
    "llm = ChatOllama(model=model_name)\n",
    "llm.temperature = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d4c760-0f23-453a-a724-ee45e5cc0515",
   "metadata": {},
   "outputs": [],
   "source": [
    "# States\n",
    "class PrivateState(BaseModel):\n",
    "    pass\n",
    "    \n",
    "class DecisionState(BaseModel):\n",
    "    article: dict = {}\n",
    "    answer_context: dict = Field(default={}, description=\"Context of the decision process from the agent\")\n",
    "    human_subjects: bool = Field(default=False, description=\"Does the article contain information about human subjects\")\n",
    "    participant_demographics: bool = Field(default=False, description=\"Does the article provide quantitative data on the number of participants and/or by sex\")\n",
    "    multi_sample: bool = Field(default=False, description=\"Does the study report individual participants or biological samples?\")\n",
    "    #one_subject: bool = Field(default=False, description=\"Does the samples provides from the same subject\")   \n",
    "    multi_cohorts: bool = Field(default=False, description=\"Are there multiple cohorts\")\n",
    "    cohorts_overlap: bool = Field(default=False, description=\"Are there individuals present in more than one cohort\")\n",
    "    dropouts_before: bool = Field(default=False, description=\"Are there participants who dropped the study before it started\")\n",
    "    dropouts_during: bool = Field(default=False, description=\"Are there participants who dropped the study after it started\") # needed?\n",
    "    droupouts_after: bool = Field(default=False, description=\"Are there participants excluded after the study ended\") # during the study or after the study ended (i.e., manual exclusion) \n",
    "    info_text: bool = Field(default=False, description=\"Is the demographic information presented in text format\")\n",
    "    info_table: bool = Field(default=False, description=\"Is the demographic information presented in table format\")\n",
    "\n",
    "\n",
    "class ResultResponse(BaseModel):\n",
    "    n_male: float = Field(default=np.nan, description=\"The total number of unique male participants reported in the paper\")\n",
    "    n_female: float = Field(default=np.nan, description=\"The total number of unique female participants reported in the paper\")\n",
    "    n_sample: float = Field(default=np.nan, description=\"The total number of unique participants reported in the paper\")\n",
    "    # some papers include only percentages. \n",
    "    # perc_male: : float = Field(default=np.nan, description=\"Percentage of male participants, optional\") \n",
    "    # perc_female: : float = Field(default=np.nan, description=\"Percentage of female participants, optional\")\n",
    "\n",
    "class FinalResponse(DecisionState, ResultResponse):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aabbaff-a095-427b-9b3d-c9744d239a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pydantic parsers\n",
    "from pydantic import BaseModel, Field, model_validator\n",
    "import json\n",
    "import ast\n",
    "\n",
    "class BooleanParser(BaseModel):\n",
    "    answer: bool = Field(description=\"Must be either 'True' or 'False'\")\n",
    "    \n",
    "    @model_validator(mode=\"before\")\n",
    "    @classmethod\n",
    "    def preprocess_input(cls, values: dict) -> dict:\n",
    "        raw_answer = values.get(\"answer\")\n",
    "        \n",
    "        if isinstance(raw_answer, str):\n",
    "            # Clean and convert string if necessary\n",
    "            raw_answer = cls._clean_and_convert_string(raw_answer)\n",
    "        \n",
    "        # Handle case where raw_answer is a dictionary with an 'answer' field\n",
    "        if isinstance(raw_answer, dict) and \"answer\" in raw_answer:\n",
    "            raw_answer = raw_answer[\"answer\"]\n",
    "        \n",
    "        # If it's still a string, check for valid \"true\"/\"false\" values\n",
    "        if isinstance(raw_answer, str):\n",
    "            stripped_answer = raw_answer.strip().lower()\n",
    "            if stripped_answer in (\"true\", \"false\"):\n",
    "                raw_answer = stripped_answer == \"true\"\n",
    "        \n",
    "        # If the answer is neither boolean nor string, raise an error\n",
    "        if not isinstance(raw_answer, bool):\n",
    "            raise ValueError(f\"Answer must be 'True' or 'False', got: {raw_answer}\")\n",
    "        \n",
    "        values[\"answer\"] = raw_answer\n",
    "        return values\n",
    "\n",
    "    @staticmethod\n",
    "    def _clean_and_convert_string(raw_answer: str) -> any:\n",
    "        raw_answer = raw_answer.strip(\"`\").strip()\n",
    "        \n",
    "        if raw_answer.startswith('```json') and raw_answer.endswith('```'):\n",
    "            # Remove the ```json``` markers\n",
    "            raw_answer = raw_answer[7:-3].strip()\n",
    "\n",
    "        # Replace 'True'/'False' to lowercase for uniformity\n",
    "        raw_answer = raw_answer.replace(\"True\", \"true\").replace(\"False\", \"false\")\n",
    "        \n",
    "        try:\n",
    "            # Try to parse as JSON\n",
    "            raw_answer = json.loads(raw_answer)\n",
    "        except json.JSONDecodeError:\n",
    "            try:\n",
    "                # Try to evaluate as a Python literal\n",
    "                raw_answer = ast.literal_eval(raw_answer)\n",
    "            except (ValueError, SyntaxError):\n",
    "                print(f\"Failed to parse raw_answer: {raw_answer}\")\n",
    "                pass\n",
    "        \n",
    "        return raw_answer\n",
    "    \n",
    "    @model_validator(mode=\"after\")\n",
    "    @classmethod\n",
    "    def validate_answer(cls, model: \"BooleanParser\") -> \"BooleanParser\":\n",
    "        if not isinstance(model.answer, bool):\n",
    "            raise ValueError(f\"Answer must be a boolean (True or False), got: {model.answer}\")\n",
    "        return model\n",
    "    \n",
    "    \n",
    "class ContextParser(BooleanParser):\n",
    "    context: str = Field(default='', description=\"Relevant sentences or data supporting the decision\")\n",
    "\n",
    "    @model_validator(mode=\"before\")\n",
    "    @classmethod\n",
    "    def preprocess_input(cls, values: dict) -> dict:\n",
    "        # First, handle BooleanParser preprocessing\n",
    "        values = super().preprocess_input(values)\n",
    "\n",
    "        # Additional preprocessing for context\n",
    "        raw_context = values.get(\"context\", \"\")\n",
    "        if isinstance(raw_context, str):\n",
    "            values[\"context\"] = raw_context.strip()\n",
    "\n",
    "        return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004682f0-2a2e-42f0-9fad-1fcca9033d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nodes\n",
    "def human_subject_decision(state: DecisionState) -> dict:\n",
    "    \"\"\"\n",
    "    Determines if the scientific article includes or considers human subjects in the study by analyzing specific sections of the document.\n",
    "    \"\"\"\n",
    "    print('Inside the human_subject_decision node')\n",
    "    \n",
    "    system_message = \"\"\"\n",
    "    You are a specialized assistant for extracting demographic data from scientific publications.\n",
    "    Use tools to extract and examine specific sections of the document.\n",
    "    \"\"\"\n",
    "    user_message = \"\"\"\n",
    "    Your task is to determine if the article involves a study on human subjects. \n",
    "    Focus on the following section: {section_header} of the document: {section_content}\n",
    "    \n",
    "    Respond with:\n",
    "    - 'True': If the document explicitly mentions human subjects.\n",
    "    - 'False': If the document does not mention human subjects or lacks enough information for a clear decision.\n",
    "\n",
    "    Important: Follow the format instructions exactly:\\n\\n{format_instructions}. \n",
    "    Fully respect the format_instruction and do not provide any additional information beyond what is requested.\n",
    "    \"\"\"\n",
    "    \n",
    "    parser = PydanticOutputParser(pydantic_object=BooleanParser)\n",
    "    \n",
    "    for section in state.article:\n",
    "        section_content = state.article[section]\n",
    "\n",
    "        if section.lower() == 'pmcid'  or section_content is None:\n",
    "            continue  # Skip if the section is not available\n",
    "        # Call the tool to extract the section\n",
    "        print(f\"Section: {section} - Nbr of word {len(section_content)}\")\n",
    "\n",
    "        chat_prompt = ChatPromptTemplate.from_messages([(\"system\", system_message), (\"user\", user_message)])\n",
    "\n",
    "        prompt_messages = chat_prompt.format_messages(section_header=section, section_content=section_content, format_instructions=parser.get_format_instructions())\n",
    "        response = llm.invoke(prompt_messages)\n",
    "#           print(response)\n",
    "\n",
    "        try:\n",
    "            # print(f\"The full answer: {response}\")\n",
    "            print(f\"The response content: {response.content}\")\n",
    "            parsed_response = parser.invoke(response.content)\n",
    "            #print(f\"Parsed response: {parsed_response.answer}\")\n",
    "\n",
    "            if parsed_response.answer == True:  # If 'True' is found, return immediately\n",
    "                return {\"human_subjects\": parsed_response.answer}\n",
    "        except ValueError as e:\n",
    "            print(f\"Error in human node: {response}\")\n",
    "            raise ValueError(\"Validation failed for model: \" + str(e))\n",
    "\n",
    "    return {\"human_subjects\": False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88dc4b8-c416-4ce9-a7d2-0936f2a3ea6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_samples(state: DecisionState) -> str:\n",
    "    \"\"\"\n",
    "    Determines if the study reports individual participants or biological samples from multiple individuals, excluding cell lines and tissue samples from the same organism.\n",
    "    \"\"\"\n",
    "    print('Inside the multi_samples node')\n",
    "\n",
    "    system_message = \"\"\"\n",
    "    You are a specialized assistant for extracting demographic data from scientific publications. \n",
    "    Use tools to extract and examine specific sections of the document.\n",
    "    \"\"\"\n",
    "    user_message = \"\"\"\n",
    "    Your task is to determine if the study reports on samples from multiple individuals. \n",
    "    Focus on the following section: {section_header} of the document: {section_content}\n",
    "    Respond with:\n",
    "    - 'True': If the study mentions human subjects, participants, or biological samples from individual organisms (excluding cell lines and tissue samples from the same organism).\n",
    "    - 'False': If the study does not involve individual organisms as participants or samples, or if it primarily uses cell lines and tissue samples from the same organism, or if there is insufficient information to make a determination.\n",
    "   \n",
    "    Here are four illustrative examples to guide you in the task:\n",
    "    \n",
    "    Example 1: \n",
    "    - Text: This study utilized HeLa cell lines to investigate the effects of drug X on cancer growth. The HeLa cells were cultured under standard laboratory conditions. \n",
    "    - Response: False\n",
    "\n",
    "    Example 2: \n",
    "    - Text: Tissue samples were collected from 15 individual patients, each diagnosed with a distinct type of skin cancer. Each sample was processed separately to ensure individual analysis.\n",
    "    - Response: True\n",
    "    \n",
    "    Example 3: \n",
    "    - Text: The study involved 100 participants who were enrolled to evaluate the efficacy of a new dietary supplement. Each participant provided a blood sample for biomarker analysis.\n",
    "    - Response: True\n",
    "    \n",
    "    Example 4: \n",
    "    - Text: Tissue samples were collected from a single patient diagnosed with liver cancer. Multiple sections from the same tumor were analyzed to assess variability within the tumor itself.\n",
    "    - Response: False\n",
    "  \n",
    "    If the answer is 'True', include relevant sentences or table excerpts from the section that support your decision in the 'context' field.\n",
    "    Important: Follow the format instructions exactly:\\n\\n{format_instructions}. \n",
    "    Fully respect the format_instruction and do not provide any additional information beyond what is requested.\n",
    "   \"\"\"\n",
    "    parser = PydanticOutputParser(pydantic_object=ContextParser)\n",
    "\n",
    "    for section in state.article:\n",
    "        section_content = state.article[section]\n",
    "\n",
    "        if section.lower() == 'pmcid'  or section_content is None:\n",
    "            continue  # Skip if the section is not available\n",
    "        # Call the tool to extract the section\n",
    "        print(f\"Section: {section} - Nbr of word {len(section_content)}\")\n",
    "\n",
    "        chat_prompt = ChatPromptTemplate.from_messages([(\"system\", system_message), (\"user\", user_message)])\n",
    "\n",
    "        prompt_messages = chat_prompt.format_messages(section_header=section, section_content=section_content, format_instructions=parser.get_format_instructions())\n",
    "        response = llm.invoke(prompt_messages)\n",
    "#           print(response)\n",
    "\n",
    "        try:\n",
    "            # print(f\"The full answer: {response}\")\n",
    "            \n",
    "            print(f\"The response content: {response.content}\")\n",
    "            parsed_response = parser.invoke(response.content)\n",
    "            #print(f\"Parsed response: {parsed_response.answer}\")\n",
    "\n",
    "            if parsed_response.answer == True:  # If 'True' is found, return immediately\n",
    "                return {\"multi_sample\": parsed_response.answer}\n",
    "        except ValueError as e:\n",
    "            print(f\"Error in human node: {response}\")\n",
    "            raise ValueError(\"Validation failed for model: \" + str(e))\n",
    "\n",
    "    return {\"multi_sample\": False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28e013e-242b-4d9d-a2ed-74e023f214f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def participant_demographics_check(state: DecisionState):\n",
    "    \"\"\"\n",
    "    Determines if the text contains information about sex and/or participant quantitative data.\n",
    "    \"\"\"\n",
    "    print('Inside the participant_demographics_check node')\n",
    "    \n",
    "    system_message = \"\"\"\n",
    "    You are a specialized assistant for extracting demographic data from scientific publications.  \n",
    "    Use tools to extract and examine specific sections of the document.\n",
    "    \"\"\"\n",
    "    user_message = \"\"\"\n",
    "    The article discusses experiments involving individual human subjects. \n",
    "    Your task is to determine the presence of information about the number of participants and whether it is disaggregated by sex or gender in the section. \n",
    "    Focus on the following section: {section_header} of the document: {section_content} \n",
    "    \n",
    "    Respond with:\n",
    "    - 'True': If the document contains information to know if some participants are males or females or if the information about the gender is given. Even if only one gender or sex can be inferred, answer True\n",
    "    - 'False': If the document does not contain information about the sex or the gender of the participants.\n",
    "    \n",
    "    Here are two illustrative examples to guide you in the task:\n",
    "\n",
    "    Example 1: \n",
    "    - Text: The study included 50 participants, comprising 30 females and 20 males, aged between 20 to 35 years.\n",
    "    - Response: True\n",
    "    Example 2: \n",
    "    - Text: \"This research involved a cohort of individuals who participated in various cognitive tests.\"\n",
    "    - Response: False\n",
    "    \n",
    "    If the answer is 'True', include relevant sentences or table excerpts from the section that support your decision in the 'context' field.\n",
    "    If the document is empty, just answer False; I will provide another section to try again.\n",
    "    \n",
    "    Important: Follow the format instructions exactly:\\n\\n{format_instructions}. \n",
    "    Fully respect the format_instruction and do not provide any additional information beyond what is requested.\n",
    "    \"\"\"\n",
    "  \n",
    "    parser = PydanticOutputParser(pydantic_object=ContextParser)\n",
    "\n",
    "    for section in state.article:\n",
    "        section_content = state.article[section]\n",
    "\n",
    "        if section.lower() == 'pmcid'  or section_content is None:\n",
    "            continue  # Skip if the section is not available\n",
    "        # Call the tool to extract the section\n",
    "        print(f\"Section: {section} - Nbr of word {len(section_content)}\")\n",
    "\n",
    "        chat_prompt = ChatPromptTemplate.from_messages([(\"system\", system_message), (\"user\", user_message)])\n",
    "\n",
    "        prompt_messages = chat_prompt.format_messages(section_header=section, section_content=section_content, format_instructions=parser.get_format_instructions())\n",
    "        response = llm.invoke(prompt_messages)\n",
    "#           print(response)\n",
    "\n",
    "        try:\n",
    "            # print(f\"The full answer: {response}\")\n",
    "            \n",
    "            print(f\"The response content: {response.content}\")\n",
    "            parsed_response = parser.invoke(response.content)\n",
    "            #print(f\"Parsed response: {parsed_response.answer}\")\n",
    "\n",
    "            if parsed_response.answer == True:  # If 'True' is found, return immediately\n",
    "                return {\"participant_demographics\": parsed_response.answer}\n",
    "        except ValueError as e:\n",
    "            print(f\"Error in human node: {response}\")\n",
    "            raise ValueError(\"Validation failed for model: \" + str(e))\n",
    "\n",
    "    return {\"participant_demographics\": False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277bbbd7-41a9-43ec-9199-090375fc6c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sex_specific_phenotype(state: DecisionState):\n",
    "    \"\"\"\n",
    "    Determines if the text contains information about sex-specific phenotype.\n",
    "    \"\"\"\n",
    "    print('Inside the participant_demographics_check node')\n",
    "    \n",
    "    system_message = \"\"\"\n",
    "    You are a specialized assistant for extracting demographic data from scientific publications.  \n",
    "    Use tools to extract and examine specific sections of the document.\n",
    "    \"\"\"\n",
    "    user_message = \"\"\"\n",
    "    The article discusses experiments involving individual human subjects. \n",
    "    Your task is to determine if the study involves sex-specific phenotypes only. \n",
    "    Focus on the following section: {section_header} of the document: {section_content} \n",
    "    \n",
    "    Respond with:\n",
    "    - 'True': If the document contains sex specific phenotype. \n",
    "    - 'False': If the document does not contain sex specific phenotype.\n",
    "    \n",
    "    Here are two illustrative examples to guide you in the task:\n",
    "\n",
    "    Example 1: \n",
    "    - Text: The study explored the genetic markers associated with breast cancer. Researchers identified hormonal influences unique participants physiology that contribute to the development and progression of the disease.\n",
    "    - Response: True\n",
    "    Example 2: \n",
    "    - Text: The research examined cognitive decline patterns in Alzheimer's disease across various age groups. \n",
    "    - Response: False\n",
    "    \n",
    "    If the answer is 'True', include relevant sentences or table excerpts from the section that support your decision in the 'context' field.\n",
    "    \n",
    "    Important: Follow the format instructions exactly:\\n\\n{format_instructions}. \n",
    "    Fully respect the format_instruction and do not provide any additional information beyond what is requested.\n",
    "    \"\"\"\n",
    "  \n",
    "    parser = PydanticOutputParser(pydantic_object=ContextParser)\n",
    "\n",
    "    for section in state.article:\n",
    "        section_content = state.article[section]\n",
    "\n",
    "        if section.lower() == 'pmcid'  or section_content is None:\n",
    "            continue  # Skip if the section is not available\n",
    "        # Call the tool to extract the section\n",
    "        print(f\"Section: {section} - Nbr of word {len(section_content)}\")\n",
    "\n",
    "        chat_prompt = ChatPromptTemplate.from_messages([(\"system\", system_message), (\"user\", user_message)])\n",
    "\n",
    "        prompt_messages = chat_prompt.format_messages(section_header=section, section_content=section_content, format_instructions=parser.get_format_instructions())\n",
    "        response = llm.invoke(prompt_messages)\n",
    "#           print(response)\n",
    "\n",
    "        try:\n",
    "            # print(f\"The full answer: {response}\")\n",
    "            \n",
    "            print(f\"The response content: {response.content}\")\n",
    "            parsed_response = parser.invoke(response.content)\n",
    "            #print(f\"Parsed response: {parsed_response.answer}\")\n",
    "\n",
    "            if parsed_response.answer == True:  # If 'True' is found, return immediately\n",
    "                return {\"participant_demographics\": parsed_response.answer}\n",
    "        except ValueError as e:\n",
    "            print(f\"Error in human node: {response}\")\n",
    "            raise ValueError(\"Validation failed for model: \" + str(e))\n",
    "\n",
    "    return {\"participant_demographics\": False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc01a81e-8bf6-4c44-8988-ae4bf8ed38b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_cohort(state: DecisionState) -> str:\n",
    "    \"\"\"\n",
    "    Determines if the text contains information about multiple cohorts, disaggregated data, or individual-level data.\n",
    "    \"\"\"\n",
    "    print('Inside the multi_cohort node')\n",
    "\n",
    "    system_message = \"\"\"\n",
    "    You are a specialized assistant for extracting demographic data from scientific publications.  \n",
    "    Use tools to extract and examine specific sections of the document.\n",
    "    \"\"\"\n",
    "    user_message = \"\"\"\n",
    "    The article discusses experiments involving individual human subjects.\n",
    "    Your task is to determine if the study involves multiple cohorts, disaggregated participants data, or individual-level data. \n",
    "    Focus on the following section: {section_header} of the document: {section_content}\n",
    "\n",
    "    Respond with:\n",
    "    - 'True': If the document contains information about multiple cohorts, disaggregated participants data, or individual-level data.\n",
    "    - 'False': If the document does not contain such information.\n",
    "    \n",
    "    Here are three illustrative examples to guide you in the task:\n",
    "\n",
    "    Example 1:\n",
    "    - Text: The study analyzed 60 patients with diabetes who were following a treatment regimen, 50 patients who were not following the treatment, and 40 patients who served as a control group.\n",
    "    - Response: True\n",
    "\n",
    "    Example 2:\n",
    "    - Text: The case study detailed the medical histories of three individual patients: John, a 45-year-old male; Mary, a 50-year-old female; and Alex, a 60-year-old male. Their treatment responses were monitored individually.\n",
    "    - Response: True\n",
    "\n",
    "    Example 3:\n",
    "    - Text: The research included a total of 100 participants, consisting of 60 females and 40 males.\n",
    "    - Response: False\n",
    "\n",
    "    If the answer is 'True', include relevant sentences or table excerpts from the section that support your decision in the 'context' field.\n",
    "\n",
    "    Important: Follow the format instructions exactly:\\n\\n{format_instructions}.\n",
    "    Fully respect the format instructions and do not provide any additional information beyond what is requested.\n",
    "    \"\"\"\n",
    "\n",
    "    parser = PydanticOutputParser(pydantic_object=ContextParser)\n",
    "    \n",
    "    for section in state.article:\n",
    "\n",
    "        # Call the tool to extract the section\n",
    "        section_content = state.article[section]\n",
    "        if section_content == \"No content available.\":\n",
    "            continue  # Skip if the section is not available\n",
    "        \n",
    "    \n",
    "        chat_prompt = ChatPromptTemplate.from_messages([(\"system\", system_message), (\"user\", user_message)])\n",
    "\n",
    "        prompt_messages = chat_prompt.format_messages(section_header=section, section_content=section_content, format_instructions=parser.get_format_instructions())\n",
    "        response = llm.invoke(prompt_messages)\n",
    "        try:\n",
    "            parsed_response = parser.invoke(response.content.strip())\n",
    "            #print(f\"Parsed response: {parsed_response.answer}\")\n",
    "            if parsed_response.answer == True:  # If 'True' is found, return immediately\n",
    "                context = state.answer_context\n",
    "                context['multi_cohort'] = {section: parsed_response.context }\n",
    "\n",
    "                return {\"multi_cohort\": parsed_response.answer,\n",
    "                        \"answer_context\": context}\n",
    "        except ValueError as e:\n",
    "            raise ValueError(\"Validation failed for model: \" + str(e))\n",
    "\n",
    "    return {\"multi_cohort\": parsed_response.answer}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9900a0a1-abe5-495a-9b2a-58617e8ee104",
   "metadata": {},
   "outputs": [],
   "source": [
    "def participants_dropout(state: DecisionState) -> str:\n",
    "    \"\"\"\n",
    "    Determines if there are several cohorts or studies in the same article.\n",
    "    \"\"\"\n",
    "    system_message = \"You are a helpful assistant that needs to extract information from a scientific article from pubmed and follow the instruction given by the user\"\n",
    "    user_message = \"\"\"Here is a scientific article. It contains one study or one experience about human subjects humans subject:\\n\\n{article}\n",
    "    In study it can happens that some participants are selected before the survey but eventually are removed for various reasons. \n",
    "    It can be also the case that participants are dropping out during the study or even after the study is done. \n",
    "    Your task is to analyse the text provided which details the method section. In there you need to figure out if there is such case of dropout.\n",
    "    If partipants (or subjects) are removed before the ss\n",
    "    \\t If the experience report to have more than one human subject or participant, answer 'True'.\n",
    "    \\t If it is not involving several humans or subjects and or several lines of tissues, cells, etc, answer 'False'.\n",
    "    Important: You need to answer the question following this format instructions:\\n\\n{format_instructions}\"\"\"\n",
    "\n",
    "    parser = PydanticOutputParser(pydantic_object=BooleanParser)\n",
    "    \n",
    "    chat_prompt = ChatPromptTemplate.from_messages([(\"system\", system_message), (\"user\", user_message)])\n",
    "\n",
    "    prompt_messages = chat_prompt.format_messages(article=state.article, format_instructions=parser.get_format_instructions())\n",
    "\n",
    "    response = llm.invoke(prompt_messages)\n",
    "    # print(f\"Straight response: {response}\")\n",
    "\n",
    "    try:\n",
    "        # print(\"Raw response content:\", response.content.strip())\n",
    "        parsed_response = parser.invoke(response.content.strip())\n",
    "        # print(\"Parsed response:\", parsed_response)  # Debugging print\n",
    "    except ValueError as e:\n",
    "        raise ValueError(\"Validation failed for model: \" + str(e))\n",
    "\n",
    "    return {\"multi_cohort\": parsed_response.answer}\n",
    "\n",
    "\n",
    "def participant_dropout_tools():\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6112972-5def-4408-a35d-909c2c664e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_information(state: DecisionState) -> dict:\n",
    "    \"\"\"\n",
    "    Extracts numerical data (e.g., number of males, females, total participants).\n",
    "    \"\"\"\n",
    "    if state.multi_cohort == True:\n",
    "        adding_message = 'There are several cohort in the article'\n",
    "    else:\n",
    "        adding_message = ''\n",
    "    system_message = \"You are a helpful assistant that needs to extract information from a scientific article from pubmed and follow the instruction given by the user\"\n",
    "    user_message = \"\"\"Here is a scientific article. It contains experience and or survey about humans subject :\\n\\n{article}\n",
    "    Your task is to understand if the reported experience are about several human subjects or about only one participant. \n",
    "    \\t If the experience report to have more than one human subject or participant, answer 'True'.\n",
    "    \\t If it is not involving several humans or subjects and or several lines of tissues, cells, etc, answer 'False'.\n",
    "    Important: You need to answer the question following this format instructions:\\n\\n{format_instructions}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d91dca4-35ec-4901-b7bb-9d523acdb758",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_numbers(state: DecisionState) -> dict:\n",
    "    \"\"\"\n",
    "    Extracts numerical data (e.g., number of males, females, total participants).\n",
    "    \"\"\"\n",
    "    result_response = ResultResponse(\n",
    "        n_male=50, \n",
    "        n_female=60, \n",
    "        n_sample=110\n",
    "    )\n",
    "    return {\n",
    "        \"n_male\": result_response.n_male,\n",
    "        \"n_female\": result_response.n_female,\n",
    "        \"n_sample\": result_response.n_sample,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c4a7d3-a2fa-44f7-9f71-2d27bf121a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def human_decision_router(state: DecisionState) -> str:\n",
    "    print(f\"In human_decision_router: {state.human_subjects}\")\n",
    "    if state.human_subjects is True:\n",
    "        return \"participant_demographics_check\"\n",
    "    elif state.human_subjects is False:\n",
    "        return END\n",
    "    else:\n",
    "        raise\n",
    "\n",
    "def participant_demographics_router(state: DecisionState) -> str:\n",
    "    print(f\"In participant_demographics_router: {state.participant_demographics}\")\n",
    "    if state.participant_demographics == True:\n",
    "        return \"multi_samples\"\n",
    "    elif state.participant_demographics == False:\n",
    "        return END\n",
    "\n",
    "def multi_sample_router(state: DecisionState) -> str:\n",
    "    print(f\"In multi_sample_router: {state.multi_sample}\")\n",
    "    if state.multi_sample == \"True\":\n",
    "        return \"multi_cohort\"\n",
    "    elif state.multi_sample == \"False\":\n",
    "        return END\n",
    "\n",
    "def multi_cohort_router(state: DecisionState) -> str:\n",
    "    print(f\"In multi_sample_router: {state.multi_sample}\")\n",
    "    if state.multi_cohort == \"True\":\n",
    "        return END\n",
    "    elif state.multi_cohort == \"False\":\n",
    "        return \"participants_dropout\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab9a0bf-b063-496d-9955-8686484c3002",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = StateGraph(DecisionState, output=FinalResponse)\n",
    "\n",
    "graph.add_node(\"human_subject_decision\", human_subject_decision)\n",
    "graph.add_node(\"participant_demographics_check\", participant_demographics_check)\n",
    "graph.add_node(\"multi_samples\", multi_samples)\n",
    "graph.add_node(\"multi_cohort\", multi_cohort)\n",
    "#graph.add_node(\"participants_dropout\", participants_dropout)\n",
    "\n",
    "\n",
    "#graph.add_node(\"calculate_numbers\", calculate_numbers)\n",
    "\n",
    "graph.add_edge(START, \"human_subject_decision\")\n",
    "graph.add_conditional_edges(\"human_subject_decision\", human_decision_router,  path_map=[\"participant_demographics_check\", END])\n",
    "graph.add_conditional_edges(\"participant_demographics_check\", participant_demographics_router, path_map=[\"multi_samples\", END])\n",
    "graph.add_conditional_edges(\"multi_samples\", multi_sample_router, path_map=[\"multi_cohort\", END])\n",
    "#graph.add_conditional_edges(\"multi_cohort\", multi_cohort_router, path_map=[\"participants_dropout\", END])\n",
    "\n",
    "#graph.add_edge(\"participants_dropout\", \"calculate_numbers\")\n",
    "#graph.add_edge(\"calculate_numbers\", END)\n",
    "graph.add_edge('multi_cohort', END)\n",
    "graph = graph.compile()\n",
    "display(Image(graph.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79037651-1399-455b-81c0-83c2bd5460ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "for article in pmcid_method:\n",
    "    initial_state = DecisionState(article=article)  # Call the initial_state like that otherwise DecisionState is not populated with default values\n",
    "    result = graph.invoke(initial_state)  \n",
    "    del result['article']\n",
    "    print(f\"Final answer: {result}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0fa886-609a-413f-aa35-7371290264c8",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb3594f-3726-4b1e-8325-c3fb83d5b35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example inputs to validate\n",
    "weird_string_test = '```json\\n{\\n  \"answer\": True\\n}\\n```'\n",
    "\n",
    "inputs = [\n",
    "    {\"answer\": \"False\"},                       # String \"False\"\n",
    "    {\"answer\": \"True\"},                        # String \"True\"\n",
    "    {\"answer\": \"true\"},                        # Case-insensitive \"true\"\n",
    "    {\"answer\": \"false\"},                       # Case-insensitive \"false\"\n",
    "    {\"answer\": '{\"answer\": \"True\"}'},          # JSON with nested \"True\" as string\n",
    "    {\"answer\": '{\"answer\": true}'},            # JSON with boolean true\n",
    "    {\"answer\": \"True   \"},                     # String with extra whitespace\n",
    "    {\"answer\": \"False   \"},                    # String with extra whitespace\n",
    "    {\"answer\": \"Not a boolean\"},               # Invalid string\n",
    "    {\"answer\": '{\"answer\": \"Not a boolean\"}'}, # Nested invalid value\n",
    "    {\"answer\": '{\"answer\": false}'},           # Nested valid boolean false\n",
    "    {\"answer\": True},                          # Python-style True\n",
    "    {\"answer\": False},                         # Python-style False\n",
    "    {\"answer\": None},                          # None input\n",
    "    {\"answer\": weird_string_test},             # Weird string with JSON-like content\n",
    "]\n",
    "\n",
    "# Test each input\n",
    "for i, input_data in enumerate(inputs):\n",
    "    try:\n",
    "        print(f\"Testing input {i + 1}: {input_data}\")\n",
    "        result = BooleanParser(**input_data)\n",
    "        print(f\"Test case {i+1}: {input_data} -> Parsed: {result}\")\n",
    "    except ValueError as e:\n",
    "        print(f\"Test case {i+1}: {input_data} -> Error: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Test case {i+1}: {input_data} -> Unexpected Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fad2a06-e693-4001-a236-89ef3cce6bff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
